# LLMz: The 15-Minute Guide

_Stop chaining tools. Start generating real code._

---

## 🚀 What is LLMz?

**The Revolutionary Approach**: Traditional agent frameworks require multiple expensive LLM calls to chain tools together. Each tool call means waiting for the LLM to understand JSON schemas (which aren't widely used on the web, so LLMs have limited training on them), generate sparse JSON that doesn't capture full function logic, parse responses, and make another call. While LLMs can return an array of tools to call, they can't run them conditionally or chain them effectively without actual code. This forces developers to create countless tool variants for minor differences, resulting in brittle systems and excessive API calls. This creates latency, complexity, and failure points.

LLMz changes everything by generating TypeScript code in a single turn that executes everything at once. No more waiting. No more JSON parsing. No more fragile tool chains.

**Code-First Philosophy**: Here's why this approach is revolutionary:

**Traditional Tool Calling** (Multiple LLM calls, no logic):

```
LLM Call 1: Generate JSON to call getWeather tool
→ Wait for response
LLM Call 2: Look at weather tool output, decide next step
→ Wait for response
LLM Call 3: Generate JSON to call sendEmail tool
→ Wait for response
LLM Call 4: Look at sendEmail tool output, return success code
→ Wait for response

Total: 4+ API calls, no conditionals, no type safety
```

**LLMz Approach** (Single turn with real code):

```typescript
const weather = await getWeather({ city: 'San Francisco' })
if (weather.temperature < 60) {
  await sendEmail({
    to: 'team@company.com',
    subject: `Cold weather alert: ${weather.temperature}°F`,
  })
}
return { action: 'done', result: 'Weather checked and team notified' }
```

**Result: 1 API call, full logic, complete type safety**

**Why TypeScript?**: LLMs have been trained on millions of TypeScript files from GitHub, Stack Overflow, and documentation. They understand:

- Variable declarations and function calls
- Conditional logic and loops
- Async/await patterns
- Type safety and interfaces
- Error handling

This deep knowledge makes LLMs incredibly reliable at generating working TypeScript code — far more reliable than generating abstract JSON tool calls.

---

## ⚡ Quick Start: Your First Agent

### Worker Mode: Pure Computation

**Installation and Setup**:

```bash
npm install llmz @botpress/client
```

> **Prerequisites**: You'll need a Botpress account and API key. Get one free at [botpress.com](https://botpress.com). Set your environment variables:
>
> ```bash
> export BOTPRESS_BOT_ID="your-bot-id"
> export BOTPRESS_TOKEN="your-api-token"
> ```

**30-Second Example**: Create a mathematical computation agent

```typescript
import { execute } from 'llmz'
import { Client } from '@botpress/client'

const client = new Client({
  botId: process.env.BOTPRESS_BOT_ID!,
  token: process.env.BOTPRESS_TOKEN!,
})

const result = await execute({
  instructions: 'Calculate the sum of all integers between 14 and 1078 that are divisible by 3, 9 or 5',
  client,
})

if (result.isSuccess()) {
  console.log('Generated code:', result.iteration.code)
  console.log('Result:', result.output)
}
```

> **Try it now**: Copy this code into a `.ts` file and run it with `npx tsx filename.ts`. LLMz will generate the algorithm and execute it in seconds.

**What Just Happened?**: Behind the scenes, the LLM generated TypeScript code like this:

```typescript
// Generated by the LLM automatically:
let sum = 0
for (let i = 14; i <= 1078; i++) {
  if (i % 3 === 0 || i % 9 === 0 || i % 5 === 0) {
    sum += i
  }
}
return { action: 'done', result: sum }
```

**The magic**: One API call, complete algorithm, instant execution. No tool definitions needed!

### Chat Mode: Interactive Conversation

**Interactive Agent Example**:

```typescript
import { execute } from 'llmz'
import { Client } from '@botpress/client'
import { CLIChat } from './utils/cli-chat' // Utility for CLI interface

const client = new Client({
  botId: process.env.BOTPRESS_BOT_ID!,
  token: process.env.BOTPRESS_TOKEN!,
})

const chat = new CLIChat()

while (await chat.iterate()) {
  await execute({
    instructions:
      'You are a helpful math tutor. Help students with problems step by step and suggest practice topics using buttons.',
    chat, // Chat mode enabled by providing chat interface
    client,
  })
}
```

**Try It**:

1. Copy the CLIChat utility from the LLMz examples folder
2. Save the code above as `math-tutor.ts`
3. Run `npx tsx math-tutor.ts`
4. Start chatting: "Can you help me solve 2x + 5 = 13?"
5. Watch the agent generate step-by-step solutions and suggest topics

The agent can solve equations, explain concepts, and generate practice problems — all through natural conversation.

---

## 🧠 Core Concepts Through Examples

### Example 1: Simple Tool Usage

**Creating Your First Tool**:

```typescript
import { Tool } from 'llmz'
import { z } from '@bpinternal/zui'

const getCurrentWeather = new Tool({
  name: 'getCurrentWeather',
  description: 'Gets current weather conditions for a specific city',
  input: z.object({
    city: z.string().describe('The city name to get weather for'),
    units: z.enum(['celsius', 'fahrenheit']).default('celsius'),
  }),
  output: z.object({
    temperature: z.number().describe('Current temperature'),
    condition: z.string().describe('Weather condition (sunny, cloudy, rainy, etc.)'),
    humidity: z.number().describe('Humidity percentage'),
  }),
  async handler({ city, units }) {
    // Simulate API call to weather service
    console.log(`Fetching weather for ${city}...`)

    // In production, call actual weather API like OpenWeatherMap
    const temp = units === 'fahrenheit' ? 72 : 22
    return {
      temperature: temp,
      condition: 'sunny',
      humidity: 65,
    }
  },
})
```

> **Tool Anatomy**: Every tool has a name, description, type-safe input/output schemas with Zui, and an async handler function. The description helps the LLM understand when and how to use the tool.

**Using the Tool with Exit**:

```typescript
import { Exit } from 'llmz'

const weatherAdviceExit = new Exit({
  name: 'weatherAdvice',
  description: 'Provides weather advice with structured output',
  schema: z.object({
    advice: z.string().describe('Human-readable weather advice'),
    umbrellaNeeded: z.boolean().describe('Whether an umbrella is recommended'),
  }),
})

const result = await execute({
  instructions: "What's the weather like in San Francisco? Should I bring a jacket?",
  tools: [getCurrentWeather],
  exits: [weatherAdviceExit],
  client,
})

if (result.isSuccess() && result.is('weatherAdvice')) {
  console.log('Advice:', result.output.advice)
  console.log('Umbrella needed:', result.output.umbrellaNeeded)
}
```

**Generated Code Preview**: Here's what the LLM actually generates behind the scenes:

**Iteration #1 - Fetch Weather Data:**

```typescript
// LLM automatically generates this TypeScript code:
const weather = await getCurrentWeather({ city: 'San Francisco', units: 'celsius' })

// Use 'think' action to let the LLM iterate and generate nuanced advice
return {
  action: 'think',
  weather,
}
```

**Iteration #2 - Generate Intelligent Advice:**

```typescript
// LLM sees the weather data from previous iteration and generates:
// Note: the 'weather' variable survives across iterations automatically
const advice = `It's ${weather.temperature}°C and ${weather.condition} in San Francisco! That's perfect weather - you won't need a jacket. The sunny conditions and comfortable temperature make it ideal for outdoor activities. Just bring sunglasses and enjoy the beautiful day!`

return {
  action: 'weatherAdvice',
  advice,
  umbrellaNeeded: weather.condition === 'rainy',
}
```

**Notice**: The LLM fetched weather data, used the `think` action to iterate and generate personalized advice based on the conditions. More intelligent than hardcoded logic!

### Example 2: Complex Multi-Tool Workflows

**Multiple Tools Working Together**:

```typescript
// Tool A: Generates complex nested data
const ToolA = new Tool({
  name: 'getData',
  description: 'Generates structured data with nested information',
  output: z.object({
    pick: z.object({
      deep: z.object({
        deep_number: z.number(),
      }),
    }),
  }),
  async handler() {
    const deep_number = Math.floor(Math.random() * 100)
    console.log('Tool A executed, returning number:', deep_number)
    return {
      pick: {
        deep: {
          deep_number,
        },
      },
    }
  },
})

// Tool B: Generates array of data for processing
const ToolB = new Tool({
  name: 'generateArray',
  description: 'Generates an array of numbers for processing',
  output: z.number().array(),
  async handler() {
    const array = Array.from({ length: 10 }, () => Math.floor(Math.random() * 100))
    console.log('Tool B executed, returning array:', array)
    return array
  },
})

// Tool C: Processes data from both tools
const ToolC = new Tool({
  name: 'processData',
  description: 'Processes combined data from other tools',
  input: z.object({
    number: z.number().describe('Number from tool A'),
    filteredArray: z.number().array().describe('Filtered numbers from tool B'),
  }),
  output: z.number().describe('The processed result'),
  async handler({ number, filteredArray }) {
    return number + filteredArray.reduce((acc, num) => acc + num, 0)
  },
})

const result = await execute({
  instructions: "Get data from tool A, filter tool B's array for numbers > 50, then process everything with tool C.",
  tools: [ToolA, ToolB, ToolC],
  client,
})
```

**The Magic**: Here's the TypeScript code the LLM generates in a single turn:

```typescript
// LLM automatically generates this complex workflow:
const dataA = await getData()
const deepNumber = dataA.pick.deep.deep_number

const arrayB = await generateArray()
const filteredArray = arrayB.filter((num) => num > 50)

const result = await processData({
  number: deepNumber,
  filteredArray: filteredArray,
})

return { action: 'exit', result }
```

Three tools coordinated with data extraction, filtering, and processing — all in one LLM call! Traditional frameworks would need 6+ API calls:

1. Call tool A → 2. Parse response → 3. Extract nested data → 4. Call tool B → 5. Parse response → 6. Filter array → 7. Call tool C → 8. Parse final response

### Example 3: Interactive Chat with UI Components

**Rich UI Components**:

```typescript
import { Component } from 'llmz'
import { z } from '@bpinternal/zui'

const PlaneTicket = new Component({
  name: 'PlaneTicket',
  description: 'A component to display a plane ticket',
  type: 'leaf', // Leaf components don't contain children
  leaf: {
    props: z.object({
      ticketNumber: z.string().describe('The unique ticket number'),
      from: z.string().describe('The departure city'),
      to: z.string().describe('The destination city'),
      date: z.string().describe('The date of the flight (YYYY-MM-DD)'),
      price: z.number().optional().describe('The price of the ticket'),
    }),
  },
  // Provide usage examples to guide the LLM
  examples: [
    {
      name: 'PlaneTicket',
      description: 'A simple plane ticket example',
      code: '<PlaneTicket from="New York" to="Los Angeles" date="2023-10-01" price={299.99} ticketNumber="ABC-0000000" />',
    },
  ],
})
```

> **Component Power**: Components are React-like UI elements with type-safe props and examples. The LLM learns how to use them from the examples and prop descriptions.

**Chat Agent with Components**:

```typescript
import { CLIChat } from './utils/cli-chat'

// Tool for purchasing tickets
const purchaseTicket = new Tool({
  name: 'purchase_ticket',
  description: 'Purchase a plane ticket',
  input: z.object({
    from: z.string().describe('The departure city'),
    to: z.string().describe('The destination city'),
    date: z.string().describe('The date of the flight (YYYY-MM-DD)'),
  }),
  output: z.object({
    price: z.number(),
    ticketNumber: z.string(),
    confirmation: z.string(),
  }),
  async handler({ from, to, date }) {
    // Simulate ticket purchase
    return {
      price: 299.99,
      ticketNumber: `TICKET-${Date.now()}`,
      confirmation: `Ticket from ${from} to ${to} on ${date} purchased successfully!`,
    }
  },
})

const chat = new CLIChat()

// Register component renderer for CLI output
chat.registerComponent(PlaneTicket, async (message) => {
  const { ticketNumber, from, to, date, price } = message.props
  console.log(`
    ✈️  FLIGHT TICKET
    Ticket Number: ${ticketNumber}
    From: ${from}
    To: ${to}
    Date: ${date}
    Price: $${price?.toFixed(2) || 'N/A'}
  `)
})

while (await chat.iterate()) {
  await execute({
    instructions:
      'You are a friendly flight booking assistant. Help users purchase tickets and display them using the PlaneTicket component.',
    tools: [purchaseTicket],
    chat, // Components automatically available in chat mode
    client,
  })
}
```

**LLM-Generated JSX**: Watch how the LLM naturally uses React-like syntax:

```typescript
// User: "I need to book a flight from NYC to LA for December 15th"

// LLM automatically generates:
yield <Text>I'll help you book a flight from New York to Los Angeles!</Text>

const ticket = await purchase_ticket({
  from: 'New York',
  to: 'Los Angeles',
  date: '2024-12-15'
})

yield <Text>Great! I've booked your flight. Here's your ticket:</Text>

yield <PlaneTicket
  ticketNumber={ticket.ticketNumber}
  from="New York"
  to="Los Angeles"
  date="2024-12-15"
  price={ticket.price}
/>

yield <Text>Your booking is confirmed! Have a great trip! ✈️</Text>

return { action: 'listen' }
```

The LLM understands JSX syntax, calls tools, handles data flow, and renders beautiful components — all naturally!

---

## 🎯 When to Use Each Mode

### Worker Mode: Perfect For

**Computational Tasks**: When you need focused, deterministic execution without user interaction:

- **Data processing and analysis**: "Process this CSV and find trends"
- **Mathematical computations**: "Calculate compound interest over 10 years"
- **Batch operations**: "Resize 100 images and upload to S3"
- **API integrations**: "Sync user data between systems"
- **File transformations**: "Convert XML to JSON with validation"

**Real Example**:

```typescript
const result = await execute({
  instructions: 'Calculate the sum of all integers between 14 and 1078 that are divisible by 3, 9 or 5',
  client,
})
// Returns: computed result in seconds
```

### Chat Mode: Perfect For

**Interactive Applications**: When you need back-and-forth conversation with rich UI:

- **Customer support agents**: Handle inquiries with contextual responses
- **Interactive tutorials**: Guide users through complex processes
- **Form filling and data collection**: Smart forms that adapt to responses
- **Multi-turn conversations**: Remember context across messages
- **Real-time assistance**: Immediate help with visual feedback

**Real Example**:

```typescript
const chat = new CLIChat()
while (await chat.iterate()) {
  await execute({
    instructions: "You're a helpful math tutor. Use buttons to suggest practice topics.",
    chat,
    client,
  })
}
// Interactive tutoring with rich UI components
```

---

## 🛠️ Essential Building Blocks

### Tools: Your Agent's Capabilities

**Tool Anatomy**: Every LLMz tool is designed for reliability and clarity:

- **Type-Safe**: Input/output validation with Zui schemas catches errors before execution
- **Retry Logic**: Automatic retry with exponential backoff handles transient failures
- **Rich Descriptions**: Detailed descriptions help LLMs understand when and how to use tools
- **Static Inputs**: Pre-fill common parameters to reduce complexity
- **Aliases**: Multiple names for the same tool for natural language flexibility

**Advanced Tool Patterns**:

```typescript
// Tool with smart retry logic
const apiTool = new Tool({
  name: 'callExternalAPI',
  description: 'Makes API calls to external services',
  input: z.object({ endpoint: z.string(), data: z.any() }),
  output: z.object({ response: z.any() }),
  async handler({ endpoint, data }) {
    // Your API logic here
    throw new Error('Network timeout') // Simulated error
  },
  retry: ({ attempt, error }) => {
    // Retry up to 3 times, but not for auth errors
    return attempt < 3 && !error.message.includes('Unauthorized')
  },
})

// Tool with static inputs (pre-configured parameters)
const webSearch = new Tool({
  name: 'search',
  description: 'Search the web for information',
  input: z.object({
    query: z.string(),
    count: z.number().default(10),
    browsePages: z.boolean().default(false),
  }),
  output: z.object({ results: z.array(z.any()) }),
  async handler({ query, count, browsePages }) {
    // Search implementation
    return { results: [] }
  },
}).setStaticInputValues({
  count: 10, // Always return 10 results
  browsePages: false, // Never auto-browse pages
})

// Tool with conditional authentication
const secureAction = new Tool({
  name: 'performSecureAction',
  description: 'Performs admin-only operations',
  input: z.object({ action: z.string() }),
  output: z.object({ success: z.boolean() }),
  async handler({ action }) {
    // Tool can access global state or context
    if (userRole !== 'admin') {
      throw new Error('Unauthorized: Admin access required')
    }
    return { success: true }
  },
})
```

### Exits: Controlling How Agents Finish

**Basic Exit Example**:

```typescript
import { Exit } from 'llmz'
import { z } from '@bpinternal/zui'

const successExit = new Exit({
  name: 'success',
  description: 'Task completed successfully with results',
  schema: z.object({
    result: z.string().describe('The final result or outcome'),
    confidence: z.number().min(0).max(1).describe('Confidence level 0-1'),
    timestamp: z.string().optional().describe('When the task completed'),
  }),
})
```

> **Exit Purpose**: Exits define how your agent can terminate execution. They ensure type-safe results and clear success conditions.

**Multiple Exits for Different Outcomes**:

```typescript
const exits = [
  new Exit({
    name: 'success',
    description: 'Task completed successfully',
    schema: z.object({
      data: z.any().describe('The processed data'),
      summary: z.string().describe('Human-readable summary'),
    }),
  }),
  new Exit({
    name: 'needsMoreInfo',
    description: 'Need additional information from user',
    schema: z.object({
      question: z.string().describe('What information is needed'),
      suggestedAnswers: z.array(z.string()).optional(),
    }),
  }),
  new Exit({
    name: 'partialSuccess',
    description: 'Task partially completed with some issues',
    schema: z.object({
      completedItems: z.array(z.string()),
      failedItems: z.array(z.string()),
      errors: z.array(z.string()),
    }),
  }),
]

// Usage in execute:
const result = await execute({
  instructions: 'Process this data file and handle any issues gracefully',
  tools: [processData, validateData],
  exits,
  client,
})

// Type-safe result handling:
if (result.isSuccess() && result.is('success')) {
  console.log('Data:', result.output.data)
  console.log('Summary:', result.output.summary)
} else if (result.is('needsMoreInfo')) {
  console.log('Question:', result.output.question)
}
```

### Objects: Grouping and State Management

**Namespace Related Tools**:

```typescript
import { ObjectInstance } from 'llmz'

// Object with state management and validation
const UserProfileObject = new ObjectInstance({
  name: 'user',
  description: 'The user profile with validated properties',
  properties: [
    {
      name: 'name',
      description: 'The name of the user',
      type: z.string().nullable(),
      value: null, // Current value
      writable: true, // Allow LLM to modify
    },
    {
      name: 'age',
      description: 'The age of the user',
      type: z.number().min(18, 'Must be at least 18 years old').max(40, 'Cannot be above 40 years old').nullable(),
      value: null,
      writable: true,
    },
    {
      name: 'email',
      description: 'The user email address',
      type: z.string().email().nullable(),
      value: null,
      writable: true,
    },
    {
      name: 'apiKey',
      description: 'Secret API key',
      type: z.string(),
      value: 'secret-key-123',
      writable: false, // Read-only for security
    },
  ],
})
```

**Usage in Generated Code**:

```typescript
// LLM automatically generates object property access:
yield <Text>Hello! Let me collect your profile information.</Text>

// Set properties with validation
user.name = 'John Doe'
user.age = 25  // Validates: must be 18-40
user.email = 'john@example.com'  // Validates: must be valid email

// Read readonly properties
const apiKey = user.apiKey  // Can read but not modify

// Validation errors are thrown automatically
try {
  user.age = 15  // Throws: "Must be at least 18 years old"
} catch (error) {
  yield <Text>Sorry, you must be at least 18 years old.</Text>
}

return { action: 'listen' }
```

**Powerful Features**:

- **State Management**: Properties persist across tool calls within execution
- **Type Safety**: All properties validated against Zui schemas
- **Read/Write Control**: Protect sensitive data with readonly properties
- **Validation**: Rich constraints with custom error messages

---

## 🚀 Building Real Applications

### Example 1: Customer Support Agent

**Complete Implementation**:

```typescript
import { CLIChat } from './utils/cli-chat'
import { ThinkSignal } from 'llmz'

// Knowledge base search tool (RAG pattern)
const searchKnowledgeBase = new Tool({
  name: 'search',
  description: 'Search company knowledge base for answers',
  input: z.string().describe('Search query for knowledge base'),
  async handler(query) {
    // Semantic search across uploaded documents
    const { passages } = await client.searchFiles({
      query,
      tags: { purpose: 'support' },
      limit: 10,
      contextDepth: 3,
      consolidate: true,
    })

    if (!passages.length) {
      throw new ThinkSignal('No results found', 'No results found in knowledge base. Escalate to human support.')
    }

    // Format results with citations
    const results = passages.map((p, i) => `[${i + 1}] ${p.content}`).join('\n\n')

    throw new ThinkSignal(
      'Found relevant information',
      `Search results:\n${results}\n\nUse this information to help the customer.`
    )
  },
})

const createTicket = new Tool({
  name: 'createTicket',
  description: 'Create support ticket for complex issues',
  input: z.object({
    issue: z.string().describe('Description of the issue'),
    priority: z.enum(['low', 'medium', 'high']).describe('Issue priority'),
    category: z.string().describe('Issue category'),
  }),
  output: z.object({
    ticketId: z.string(),
    estimatedResolution: z.string(),
  }),
  async handler({ issue, priority, category }) {
    const ticketId = `TICKET-${Date.now()}`
    const estimatedResolution = priority === 'high' ? '2 hours' : '24 hours'

    console.log(`Created ${priority} priority ticket: ${ticketId}`)
    return { ticketId, estimatedResolution }
  },
})

// Support UI components
const SupportCard = new Component({
  name: 'SupportCard',
  description: 'Display support information in a card format',
  type: 'leaf',
  leaf: {
    props: z.object({
      title: z.string(),
      content: z.string(),
      actionLabel: z.string().optional(),
      urgency: z.enum(['low', 'medium', 'high']).optional(),
    }),
  },
})

const chat = new CLIChat()

// Register component renderer
chat.registerComponent(SupportCard, async (message) => {
  const { title, content, actionLabel, urgency } = message.props
  const urgencyColor = urgency === 'high' ? chalk.red : urgency === 'medium' ? chalk.yellow : chalk.green

  console.log(`
    📋 ${chalk.bold(title)}
    ${content}
    ${actionLabel ? `🔗 ${actionLabel}` : ''}
    ${urgency ? urgencyColor(`⚠️ Priority: ${urgency}`) : ''}
  `)
})

// Run support agent
while (await chat.iterate()) {
  await execute({
    instructions: `You are TechCorp's helpful customer support agent. 
    - Always search the knowledge base first for answers
    - Provide helpful solutions using SupportCard components  
    - Create tickets for complex issues that can't be resolved
    - Be empathetic and professional in all interactions
    - Use inline citations when referencing knowledge base results`,
    tools: [searchKnowledgeBase, createTicket],
    chat,
    client,
  })
}
```

**Key Features Showcase**:

```typescript
// User: "I can't access my account after the password reset"

// LLM generates:
const searchResults = await search('password reset account access login')

// ThinkSignal provides context, then LLM continues:
yield <SupportCard
  title="Password Reset Issue"
  content="I found instructions for password reset issues. Here's how to regain access to your account:"
  urgency="medium"
/>

yield <Text>
1. Check your email (including spam folder) for the reset link
2. The reset link expires after 24 hours
3. Make sure to use a strong password with 8+ characters

If these steps don't work, I'll create a priority ticket for you.
</Text>

yield <Button>These steps worked!</Button>
yield <Button>Still having trouble</Button>

return { action: 'listen' }

// If user still has trouble:
const ticket = await createTicket({
  issue: 'Password reset not working - user cannot access account',
  priority: 'high',
  category: 'authentication'
})

yield <SupportCard
  title="Support Ticket Created"
  content={`Ticket ${ticket.ticketId} created. Our team will contact you within ${ticket.estimatedResolution}.`}
  urgency="high"
/>
```

**Demonstrated Features**:

- **Smart Search**: Automatic knowledge base querying with ThinkSignal
- **Conditional Logic**: Different paths based on search results and user responses
- **Rich UI**: Support cards with urgency indicators and action buttons
- **Escalation Flow**: Seamless transition from self-service to human support
- **Context Retention**: Conversation flows naturally with full context

### Example 2: Data Analysis Pipeline

**Worker Mode Pipeline**:

```typescript
// File system operations
const fileSystem = makeFileSystem(client)

// CSV processing tool
const processCSV = new Tool({
  name: 'processCSV',
  description: 'Process CSV data and extract insights',
  input: z.object({
    csvContent: z.string().describe('Raw CSV content'),
    analysisType: z.string().describe('Type of analysis to perform'),
  }),
  output: z.object({
    monthlyGrowth: z.array(z.object({ month: z.string(), growth: z.number() })),
    topProducts: z.array(z.object({ product: z.string(), sales: z.number() })),
    insights: z.array(z.string()),
  }),
  async handler({ csvContent, analysisType }) {
    // Simulate CSV processing
    console.log(`Processing ${csvContent.split('\n').length} rows of data...`)

    return {
      monthlyGrowth: [
        { month: 'Jan', growth: 0.15 },
        { month: 'Feb', growth: 0.08 },
        { month: 'Mar', growth: 0.22 },
      ],
      topProducts: [
        { product: 'Widget Pro', sales: 45000 },
        { product: 'Device X', sales: 38000 },
        { product: 'Tool Kit', sales: 29000 },
      ],
      insights: [
        'Strong Q1 performance with 15% average growth',
        'Widget Pro leads sales by significant margin',
        'March showed exceptional 22% growth spike',
      ],
    }
  },
})

const generateReport = new Tool({
  name: 'generateReport',
  description: 'Generate formatted analysis report',
  input: z.object({
    data: z.any().describe('Processed analysis data'),
    title: z.string().describe('Report title'),
  }),
  output: z.object({
    report: z.string().describe('Formatted report content'),
    summary: z.string().describe('Executive summary'),
  }),
  async handler({ data, title }) {
    const report = `
# ${title}

## Monthly Growth Analysis
${data.monthlyGrowth.map((m) => `- ${m.month}: ${(m.growth * 100).toFixed(1)}%`).join('\n')}

## Top Performing Products
${data.topProducts.map((p, i) => `${i + 1}. ${p.product}: $${p.sales.toLocaleString()}`).join('\n')}

## Key Insights
${data.insights.map((insight) => `• ${insight}`).join('\n')}
    `

    return {
      report,
      summary: `Analysis complete: ${data.monthlyGrowth.length} months analyzed, ${data.topProducts.length} top products identified`,
    }
  },
})

// Execute complete analysis pipeline
const result = await execute({
  instructions: `
    Analyze sales data comprehensively:
    1. Read the sales data from "q1-sales.csv" 
    2. Process the CSV data to calculate growth rates and identify trends
    3. Generate insights about product performance and seasonality
    4. Create a professional analysis report with key findings
    5. Save the report to "q1-analysis-report.md"
  `,
  objects: [fileSystem],
  tools: [processCSV, generateReport],
  exits: [
    new Exit({
      name: 'analysisComplete',
      schema: z.object({
        reportPath: z.string(),
        summary: z.string(),
        keyFindings: z.array(z.string()),
      }),
    }),
  ],
  client,
})

if (result.isSuccess()) {
  console.log('Analysis completed:', result.output.summary)
  console.log('Report saved to:', result.output.reportPath)
}
```

**What Makes This Powerful**:

```typescript
// LLM generates a complete data pipeline in one execution:
const csvData = await fs.readFile('q1-sales.csv')
console.log('Loaded sales data from file')

const analysis = await processCSV({
  csvContent: csvData,
  analysisType: 'quarterly_performance',
})

// LLM automatically generates insights and validation
const insights = []
for (const month of analysis.monthlyGrowth) {
  if (month.growth > 0.15) {
    insights.push(`Exceptional growth in ${month.month}: ${(month.growth * 100).toFixed(1)}%`)
  }
}

if (analysis.topProducts[0].sales > 40000) {
  insights.push(`${analysis.topProducts[0].product} is the clear market leader`)
}

const report = await generateReport({
  data: analysis,
  title: 'Q1 2024 Sales Performance Analysis',
})

await fs.writeFile('q1-analysis-report.md', report.report)

return {
  action: 'analysisComplete',
  reportPath: 'q1-analysis-report.md',
  summary: report.summary,
  keyFindings: [...analysis.insights, ...insights],
}
```

**Revolutionary Benefits**:

- **Single Execution**: Entire pipeline runs in one LLM call - no orchestration needed
- **Smart Analysis**: LLM generates insights and business logic, not just data processing
- **File Operations**: Seamless integration with file system through object namespacing
- **Error Handling**: Built-in validation and error recovery throughout the pipeline
- **Type Safety**: All data flows safely between pipeline steps with full validation
- **Business Logic**: LLM understands business context and generates relevant insights

### Example 3: Multi-Agent System

**Agent Orchestration**:

```typescript
// Define specialized agents with different capabilities
const agents = [
  {
    name: 'MainAgent',
    description: 'Customer service coordinator and general inquiries',
    positive_examples: ['General questions', 'Account information', 'Billing inquiries'],
    instructions:
      'You are the main customer service agent. Help with general inquiries and route complex issues to specialists.',
    tools: [generalHelp, accountLookup],
  },
  {
    name: 'HRAgent',
    description: 'Human Resources specialist for employee matters',
    positive_examples: ['Employee benefits', 'Leave requests', 'HR policies'],
    instructions: 'You are an HR specialist. Handle employee-related inquiries with confidentiality and care.',
    tools: [hrPolicies, leaveManagement, benefitsInfo],
  },
  {
    name: 'ITAgent',
    description: 'Technical support for IT issues',
    positive_examples: ['Password resets', 'Software issues', 'Hardware problems'],
    instructions: 'You are an IT support specialist. Solve technical problems efficiently.',
    tools: [passwordReset, systemDiagnostics, softwareSupport],
  },
  {
    name: 'SalesAgent',
    description: 'Sales and product information specialist',
    positive_examples: ['Product information', 'Pricing', 'Sales inquiries'],
    instructions: 'You are a sales specialist. Help customers with product information and sales.',
    tools: [productCatalog, pricingInfo, salesQuotes],
  },
]

// Multi-agent orchestration system
class MultiAgentOrchestrator {
  private currentAgent: string

  constructor(
    private agents: Agent[],
    initialAgent: string
  ) {
    this.currentAgent = initialAgent
  }

  get context() {
    const agent = this.agents.find((a) => a.name === this.currentAgent)
    const availableAgents = this.agents.filter((a) => a.name !== this.currentAgent)

    return {
      instructions: `${agent.instructions}
      
      Available specialists for handoff:
      ${availableAgents.map((a) => `- ${a.name}: ${a.description}`).join('\n')}
      
      Use the 'handoff' exit to transfer complex inquiries to the appropriate specialist.`,
      tools: agent.tools,
      exits: [
        new Exit({
          name: 'handoff',
          description: 'Transfer to another specialist agent',
          schema: z.object({
            targetAgent: z.string(),
            reason: z.string(),
            context: z.string(),
          }),
        }),
        new Exit({ name: 'resolved', schema: z.object({ solution: z.string() }) }),
      ],
    }
  }

  hasHandedOff(result: ExecutionResult): boolean {
    if (result.is('handoff')) {
      console.log(`🔄 Handoff: ${this.currentAgent} → ${result.output.targetAgent}`)
      console.log(`Reason: ${result.output.reason}`)
      this.currentAgent = result.output.targetAgent
      return true
    }
    return false
  }
}

// Create orchestrator and run multi-agent system
const orchestrator = new MultiAgentOrchestrator(agents, 'MainAgent')
const chat = new CLIChat()

while (true) {
  const result = await execute({
    ...orchestrator.context, // Dynamic agent context
    client,
    chat,
  })

  if (!orchestrator.hasHandedOff(result)) {
    // No handoff - wait for next user input
    await chat.prompt()
  }
  // Continue loop with new agent context after handoff
}
```

**Key Features**:

- **Dynamic Context**: Each agent has specialized tools and instructions
- **Seamless Handoffs**: Agents intelligently route complex inquiries to specialists
- **Conversation Continuity**: Context preserved across agent transitions
- **Scalable Architecture**: Easily add new specialized agents
- **Automatic Routing**: LLM decides when and where to hand off conversations

---

## 🔒 Production Considerations

### Security

**Built-in Security Features**:

- **Sandboxed Execution**: Code runs in `isolated-vm` with no access to host system
- **Input Validation**: All tool inputs validated against Zui schemas before execution
- **Stack Trace Cleaning**: Internal framework details removed from error messages
- **Timeout Protection**: Automatic termination of long-running or infinite code
- **Memory Limits**: Prevents memory exhaustion attacks
- **No File System Access**: Unless explicitly provided through tools

**Best Practices**:

- **Validate Tool Inputs**: Use Zui schemas for strong type validation
- **Protect Sensitive Data**: Use readonly variables for API keys and credentials
- **Error Handling**: Implement proper try/catch in tool handlers
- **Monitor Execution**: Use `onTrace` hooks to track agent behavior
- **Rate Limiting**: Implement limits on tool calls and execution time
- **Audit Logging**: Log all tool executions for security analysis

### Performance

**Optimization Strategies**:

- **Minimize Tokens**: Use concise tool descriptions and clear instructions
- **Code Caching**: LLMz automatically caches compiled code between executions
- **Lazy Tool Loading**: Only provide tools that are likely to be used
- **Efficient Prompts**: Clear, specific instructions reduce generation time
- **Parallel Execution**: Use multiple agents for independent tasks
- **Result Caching**: Cache expensive tool call results when appropriate

---

## 🎓 Next Steps

### Dive Deeper

**Advanced Topics to Explore**:

- **Snapshots**: Pause and resume long-running executions for workflows
- **Hooks**: Monitor and control execution flow with `onTrace`, `onExit` callbacks
- **Custom Components**: Build domain-specific UI elements with JSX
- **Citations**: Implement RAG patterns with source tracking and references
- **Multi-Agent Systems**: Orchestrate specialized agents with handoff patterns
- **ThinkSignal**: Force agent reflection and variable inspection

### Learning Path

**Recommended Progression**:

1. **🎯 Start Simple**: Build basic worker mode agents with mathematical computations
2. **💬 Add Interaction**: Create chat agents with CLIChat and basic components
3. **🔧 Master Tools**: Learn tool patterns, retry logic, and static inputs
4. **📊 Complex Workflows**: Multi-tool coordination and data processing pipelines
5. **🎨 Rich UIs**: Custom components, JSX, and interactive interfaces
6. **🔒 Production Ready**: Security best practices, monitoring, and testing
7. **🤖 Advanced Patterns**: Multi-agent systems, snapshots, and specialized workflows

### Community and Resources

**Get Help and Connect**:

- 📚 **Complete Guide**: `/docs/llmz-complete-guide.md` - Comprehensive documentation
- 🔬 **Examples Repository**: `/examples/` - 20+ practical examples in the LLMz repo
- 🏃‍♂️ **Quick Start**: Run `pnpm start` in examples directory to explore
- 🐛 **Report Issues**: GitHub Issues for bugs and feature requests
- 🎮 **Try Examples**: Start with `01_chat_basic` and `11_worker_minimal`
- 🌟 **Production Use**: LLMz powers millions of agents at Botpress

---

## 🌟 Why Developers Love LLMz

**Developer Testimonials**:

> "LLMz reduced our agent response time from 30 seconds to 3 seconds by eliminating tool chaining."
> — Senior Engineer, E-commerce Platform

> "The TypeScript-first approach means our entire team can contribute to agent development."  
> — Engineering Manager, SaaS Company

> "Finally, an agent framework that feels like modern software development."
> — Full-Stack Developer, AI Startup

**Key Benefits Summary**:

- ⚡ **10x Faster**: Single-turn execution vs multiple API calls
- 🔒 **Production Ready**: Security, monitoring, and error handling built-in
- 🧑‍💻 **Developer Friendly**: TypeScript ecosystem and tooling
- 🎨 **Rich UIs**: React-like component system for interactive experiences
- 📈 **Scalable**: From simple scripts to complex multi-agent systems
- 🛡️ **Type Safe**: End-to-end type safety with Zui schemas
- 🚀 **Battle Tested**: Powers millions of agents in production at Botpress

---

_Ready to build your first LLMz agent? Start with the examples above and explore the complete guide for advanced patterns._
